{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is about prediction cardiovascular disease based on systolic blood pressure and Diastolic blood pressure. A 1 classification means the person has a cardiovascular disease and 0 means they don't. There are approximately 70,000 data values in total and will be split in a 7 to 3 ratio for training and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"cardio_train.csv\")\n",
    "\n",
    "a = train.to_numpy()\n",
    "\n",
    "X = a[:, [5,6]]\n",
    "\n",
    "y = a[:, 12]\n",
    "y=y.astype('int')\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation:\n",
      "\n",
      "Accuracy: 0.57 Stdev: 0.092 [Perceptron]\n",
      "Accuracy: 0.71 Stdev: 0.006 [Logestic Regression]\n",
      "Accuracy: 0.71 Stdev: 0.01 [KNN]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipe1 = make_pipeline(StandardScaler(), Perceptron(eta0=0.1, random_state=1))\n",
    "\n",
    "pipe2 = make_pipeline(StandardScaler(), LogisticRegression(C=2000, random_state=5, solver='lbfgs'))\n",
    "#pipe2 = make_pipeline(StandardScaler(), SVC(kernel='rbf', random_state=1, gamma=1, C=1000000.0))\n",
    "\n",
    "#pipe3 = make_pipeline(StandardScaler(), SVC(kernel='rbf', random_state=1, gamma=1, C=1000000.0))\n",
    "pipe3 = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=20,\n",
    "                                                             p=3,\n",
    "                                                             metric='minkowski'))\n",
    "\n",
    "clf_labels = ['Perceptron', 'Logestic Regression', 'KNN']\n",
    "\n",
    "print('10-fold cross validation:\\n')\n",
    "for clf, label in zip([pipe1, pipe2, pipe3], clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=10,\n",
    "                             scoring='accuracy')\n",
    "    print(\"Accuracy: \" + str(round(scores.mean(), 2)) + \n",
    "          \" Stdev: \" + str(round(scores.std(), 3)) +\n",
    "          \" [\" + label + \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57 Stdev: 0.092 [Perceptron]\n",
      "Accuracy: 0.71 Stdev: 0.006 [Logestic Regression]\n",
      "Accuracy: 0.71 Stdev: 0.01 [KNN]\n",
      "Accuracy: 0.71 Stdev: 0.009 [Majority voting]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mv_clf = VotingClassifier(estimators=[('p', pipe1), ('dt', pipe2), ('kn', pipe3)])\n",
    "\n",
    "clf_labels += ['Majority voting']\n",
    "all_clf = [pipe1, pipe2, pipe3, mv_clf]\n",
    "\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=10,\n",
    "                             scoring='accuracy')\n",
    "    print(\"Accuracy: \" + str(round(scores.mean(), 2)) + \n",
    "          \" Stdev: \" + str(round(scores.std(), 3)) +\n",
    "          \" [\" + label + \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 8642\n",
      "Out of a total of: 21000\n",
      "Accuracy: 0.5884761904761905\n"
     ]
    }
   ],
   "source": [
    "pipe1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe1.predict(X_test)\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', pipe1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 5999\n",
      "Out of a total of: 21000\n",
      "Accuracy: 0.7143333333333334\n"
     ]
    }
   ],
   "source": [
    "pipe2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe2.predict(X_test)\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', pipe2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 6451\n",
      "Out of a total of: 21000\n",
      "Accuracy: 0.6928095238095238\n"
     ]
    }
   ],
   "source": [
    "pipe3.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe3.predict(X_test)\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', pipe3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test set examples: 5988\n",
      "Out of a total of: 21000\n",
      "Accuracy: 0.7148571428571429\n"
     ]
    }
   ],
   "source": [
    "mv_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mv_clf.predict(X_test)\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', mv_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ensemble and Logistic regression pipeline performed the best on the test dataset with the K nearest neighbour close behind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
